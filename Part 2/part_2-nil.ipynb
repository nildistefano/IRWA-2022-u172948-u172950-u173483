{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------- #\n",
    "# SON LOS IMPORTS DEL LAB ANTERIOR, LOS DESCOMENTAMOS A MEDIDA QUE LOS VAYAMOS USANDO #\n",
    "# ----------------------------------------------------------------------------------- #\n",
    "\n",
    "# from collections import defaultdict\n",
    "from array import array\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "# # nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "from numpy import linalg as la\n",
    "# import json\n",
    "# import random\n",
    "# import re\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the processed tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Url</th>\n",
       "      <th>Clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc_1</td>\n",
       "      <td>1575918182698979328</td>\n",
       "      <td>So this will keep spinning over us until 7 pm…...</td>\n",
       "      <td>suzjdean</td>\n",
       "      <td>Fri Sep 30 18:39:08 +0000 2022</td>\n",
       "      <td>['HurricaneIan']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/suzjdean/status/1575918182...</td>\n",
       "      <td>['keep', 'spin', 'us', 'away', 'alreadi', 'hur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc_2</td>\n",
       "      <td>1575918151862304768</td>\n",
       "      <td>Our hearts go out to all those affected by #Hu...</td>\n",
       "      <td>lytx</td>\n",
       "      <td>Fri Sep 30 18:39:01 +0000 2022</td>\n",
       "      <td>['HurricaneIan']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/lytx/status/15759181518623...</td>\n",
       "      <td>['heart', 'go', 'affect', 'hurricaneian', 'wis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Document                   Id  \\\n",
       "0    doc_1  1575918182698979328   \n",
       "1    doc_2  1575918151862304768   \n",
       "\n",
       "                                                Text  Username  \\\n",
       "0  So this will keep spinning over us until 7 pm…...  suzjdean   \n",
       "1  Our hearts go out to all those affected by #Hu...      lytx   \n",
       "\n",
       "                             Date          Hashtags Mentions  Likes  Retweets  \\\n",
       "0  Fri Sep 30 18:39:08 +0000 2022  ['HurricaneIan']      NaN      0         0   \n",
       "1  Fri Sep 30 18:39:01 +0000 2022  ['HurricaneIan']      NaN      0         0   \n",
       "\n",
       "                                                 Url  \\\n",
       "0  https://twitter.com/suzjdean/status/1575918182...   \n",
       "1  https://twitter.com/lytx/status/15759181518623...   \n",
       "\n",
       "                                          Clean_text  \n",
       "0  ['keep', 'spin', 'us', 'away', 'alreadi', 'hur...  \n",
       "1  ['heart', 'go', 'affect', 'hurricaneian', 'wis...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder = '../output/'\n",
    "data = pd.read_csv(output_folder + \"lab1_tweets_df.csv\", sep='|')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_terms(line):\n",
    "    \"\"\"\n",
    "    Preprocess the article text (title + body) removing stop words, stemming,\n",
    "    transforming in lowercase and return the tokens of the text.\n",
    "    \n",
    "    Argument:\n",
    "    line -- string (text) to be preprocessed\n",
    "    \n",
    "    Returns:\n",
    "    line - a list of tokens corresponding to the input text after the preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    ## START CODE\n",
    "    line=  line.lower() ## Transform in lowercase\n",
    "    line=  line.split() ## Tokenize the text to get a list of terms\n",
    "    line= [x for x in line if x not in stop_words]  ##eliminate the stopwords (HINT: use List Comprehension)\n",
    "    line= [stemmer.stem(x) for x in line] ## perform stemming (HINT: use List Comprehension)\n",
    "    ## END CODE\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_tfidf(dataframe):\n",
    "    \"\"\"\n",
    "    Implement the inverted index and compute tf, df and idf\n",
    "    \n",
    "    Argument:\n",
    "    dataframe -- DataFrame containing tweet information\n",
    "    \n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
    "    list of document these keys appears in (and the positions) as values.\n",
    "    tf - normalized term frequency for each term in each document\n",
    "    df - number of documents each term appear in\n",
    "    idf - inverse document frequency of each term\n",
    "    \"\"\"\n",
    "    num_documents = dataframe.shape[0]\n",
    "    index = defaultdict(list)\n",
    "    tf = defaultdict(list)  # term frequencies of terms in documents (documents in the same order as in the main index)\n",
    "    df = defaultdict(int)   # document frequencies of terms in the corpus\n",
    "    idf = defaultdict(float)\n",
    "    for row in dataframe.iterrows():\n",
    "        doc_id = row[1]['Document']\n",
    "        terms = row[1]['Clean_text']  \n",
    "        terms = eval(terms)\n",
    "        \n",
    "        ## ===============================================================        \n",
    "        ## create the index for the **current page** and store it in current_page_index\n",
    "        ## current_page_index ==> { ‘term1’: [current_doc, [list of positions]], ...,‘term_n’: [current_doc, [list of positions]]}\n",
    "\n",
    "        ## Example: if the curr_doc has id 1 and his text is \n",
    "        ##\"web retrieval information retrieval\":\n",
    "\n",
    "        ## current_page_index ==> { ‘web’: [1, [0]], ‘retrieval’: [1, [1,4]], ‘information’: [1, [2]]}\n",
    "\n",
    "        ## the term ‘web’ appears in document 1 in positions 0, \n",
    "        ## the term ‘retrieval’ appears in document 1 in positions 1 and 4\n",
    "        ## ===============================================================\n",
    "\n",
    "        current_page_index = {}\n",
    "\n",
    "        for position, term in enumerate(terms):  ## terms contains page_title + page_text\n",
    "            try:\n",
    "                # if the term is already in the dict append the position to the corresponding list\n",
    "                current_page_index[term][1].append(position) \n",
    "            except:\n",
    "                # Add the new term as dict key and initialize the array of positions and add the position\n",
    "                current_page_index[term]=[doc_id, [position]]\n",
    "                \n",
    "        #normalize term frequencies\n",
    "        # Compute the denominator to normalize term frequencies (formula 2 above)\n",
    "        # norm is the same for all terms of a document.\n",
    "        norm = 0\n",
    "        for term, posting in current_page_index.items():\n",
    "            # posting will contain the list of positions for current term in current document. \n",
    "            # posting ==> [current_doc, [list of positions]] \n",
    "            # you can use it to infer the frequency of current term.\n",
    "            norm += len(posting[1]) ** 2\n",
    "        norm = math.sqrt(norm)\n",
    "\n",
    "        # calculate the tf(dividing the term frequency by the above computed norm) and df weights\n",
    "        for term, posting in current_page_index.items():\n",
    "            # append the tf for current term (tf = term frequency in current doc/norm)\n",
    "            tf[term].append(np.round(len(posting[1])/norm,4)) ## SEE formula (1) above\n",
    "            #increment the document frequency of current term (number of documents containing the current term)\n",
    "            df[term] = df[term]+1 # increment DF for current term\n",
    "\n",
    "        #merge the current page index with the main index\n",
    "        for term_page, posting_page in current_page_index.items():\n",
    "            index[term_page].append(posting_page)\n",
    "\n",
    "        # Compute IDF following the formula (3) above. HINT: use np.log\n",
    "        for term in df:\n",
    "            idf[term] = np.round(np.log(float(num_documents/df[term])), 4)\n",
    "\n",
    "    return index, tf, df, idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to create the index: 299.84 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "new_index, tf, df, idf = create_index_tfidf(data)\n",
    "print(\"Total time to create the index: {} seconds\" .format(np.round(time.time() - start_time, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words analysis in the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>DF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hurricaneian</td>\n",
       "      <td>3988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>florida</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>hurrican</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>ian</td>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>help</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>amp</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>storm</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>carolina</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>flood</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>power</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>south</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>make</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>landfal</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>wind</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>damag</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>peopl</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>safe</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>get</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>impact</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>go</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word    DF\n",
       "5    hurricaneian  3988\n",
       "72        florida   881\n",
       "47       hurrican   793\n",
       "70            ian   781\n",
       "211          help   386\n",
       "122           amp   362\n",
       "25          storm   352\n",
       "87       carolina   297\n",
       "303         flood   289\n",
       "293         power   275\n",
       "86          south   260\n",
       "77           make   251\n",
       "78        landfal   245\n",
       "109          wind   238\n",
       "48          damag   231\n",
       "258         peopl   229\n",
       "15           safe   219\n",
       "388           get   216\n",
       "309        impact   214\n",
       "7              go   210"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ============================= ##\n",
    "## show top DF in the collection ##\n",
    "## ============================= ##\n",
    "\n",
    "word = []\n",
    "word_df = []\n",
    "for item in df.items():\n",
    "    word.append(item[0])\n",
    "    word_df.append(item[1])\n",
    "\n",
    "document_frequency_df = pd.DataFrame(list(zip(word,word_df)), columns=['Word', 'DF'])\n",
    "document_frequency_df.sort_values(by='DF', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"Floodings in South Carolina\", \n",
    "    \"HuracaineIan disaster\", \n",
    "    \"Damage of HuracaineIan\", \n",
    "    \"Florida floodings\", \n",
    "    \"Storm and wind in Florida\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our grand trouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_documents(terms, docs, index, idf, tf):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "    \n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "    \n",
    "    Returns:\n",
    "    list of ranked documents\n",
    "    \"\"\"\n",
    "\n",
    "    # I'm interested only on the element of the docVector corresponding to the query terms \n",
    "    # The remaining elements would became 0 when multiplied to the query_vector\n",
    "    doc_vectors = defaultdict(lambda: [0] * len(terms)) # I call doc_vectors[k] for a nonexistent key k, the key-value pair (k,[0]*len(terms)) will be automatically added to the dictionary\n",
    "    query_vector = [0] * len(terms)\n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = collections.Counter(terms)  # get the frequency of each term in the query. \n",
    "\n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "\n",
    "    for termIndex, term in enumerate(terms):  #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        ## Compute tf*idf(normalize TF as done with documents)\n",
    "        query_vector[termIndex]=query_terms_count[term]/query_norm *idf[term]\n",
    "\n",
    "        # Generate doc_vectors for matching docs\n",
    "        for doc_index, (doc, postings) in enumerate(index[term]):\n",
    "\n",
    "            #tf[term][0] will contain the tf of the term \"term\" in the doc 26            \n",
    "            if doc in docs:\n",
    "                doc_vectors[doc][termIndex] = tf[term][doc_index] * idf[term]\n",
    "    \n",
    "    # Calculate the score of each doc \n",
    "    # compute the cosine similarity between queyVector and each docVector:\n",
    "    \n",
    "    doc_scores=[[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items() ]\n",
    "    doc_scores.sort(reverse=True)\n",
    "    #print document titles instead if document id's\n",
    "    #result_docs=[ title_index[x] for x in result_docs ]\n",
    "    if len(doc_scores) == 0:\n",
    "        print(\"No results found for query\")\n",
    "    #print ('\\n'.join(result_docs), '\\n')\n",
    "    return doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tf_idf(query, index):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain any of the query terms. \n",
    "    So, we will get the list of documents for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = build_terms(query)\n",
    "    docs = set()\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain \"term\"                        \n",
    "            term_docs=[posting[0] for posting in index[term]]\n",
    "            \n",
    "            # docs = docs Union term_docs\n",
    "            docs = docs.union(term_docs)\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    ranked_docs = rank_documents(query, docs, index, idf, tf)\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tf_idf_subset(query, index, subset):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain any of the query terms. \n",
    "    So, we will get the list of documents for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = build_terms(query)\n",
    "    docs = set()\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain \"term\" and are in the subset.                       \n",
    "            term_docs=[posting[0] for posting in index[term] if posting[0] in subset]\n",
    "            \n",
    "            # docs = docs Union term_docs\n",
    "            docs = docs.union(term_docs)\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    ranked_docs = rank_documents(query, docs, index, idf, tf)\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Query:  Floodings in South Carolina\n",
      "Is this document relevant to the query? 0 for no, 1 for yes:\n",
      "South Carolina #HurricaneIan https://t.co/yTA4dFUC2V\n",
      "==========\n",
      "==========\n",
      "Query:  Floodings in South Carolina\n",
      "Is this document relevant to the query? 0 for no, 1 for yes:\n",
      "Flooding in Garden City, South Carolina \n",
      "\n",
      "#GardenCity #SouthCarolina #HurricaneIan https://t.co/5W328kjWkH\n",
      "==========\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Desktop\\Coding\\IRWA\\IRWA-2022-u172948-u172950-u173483\\Part 2\\part_2-nil.ipynb Celda 18\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/Coding/IRWA/IRWA-2022-u172948-u172950-u173483/Part%202/part_2-nil.ipynb#X52sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m==========\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/Coding/IRWA/IRWA-2022-u172948-u172950-u173483/Part%202/part_2-nil.ipynb#X52sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m rate \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Desktop/Coding/IRWA/IRWA-2022-u172948-u172950-u173483/Part%202/part_2-nil.ipynb#X52sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m rate \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(rate)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/Coding/IRWA/IRWA-2022-u172948-u172950-u173483/Part%202/part_2-nil.ipynb#X52sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m ratings[(doc[\u001b[39m1\u001b[39m],query_id)] \u001b[39m=\u001b[39m rate\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/Coding/IRWA/IRWA-2022-u172948-u172950-u173483/Part%202/part_2-nil.ipynb#X52sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m relevance[(doc[\u001b[39m1\u001b[39m],query_id)] \u001b[39m=\u001b[39m doc[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "queries = queries\n",
    "top = 2\n",
    "ratings = dict()\n",
    "relevance = dict()\n",
    "\n",
    "query_id = 0\n",
    "for query in queries:\n",
    "    ranked_docs = search_tf_idf(queries[query_id], new_index)\n",
    "    for doc in ranked_docs[:top]:\n",
    "        print(\"==========\")\n",
    "        print(\"Query: \",query)\n",
    "        print(\"Is this document relevant to the query? 0 for no, 1 for yes:\")\n",
    "        print(data[data['Document']==doc[1]]['Text'].iloc[0])\n",
    "        print(\"==========\")\n",
    "        rate = input()\n",
    "        rate = float(rate)\n",
    "        ratings[(doc[1],query_id)] = rate\n",
    "        relevance[(doc[1],query_id)] = doc[0]\n",
    "    print(ratings)\n",
    "    query_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = [key[0] for key in ratings.keys()]\n",
    "query_id = [key[1] for key in ratings.keys()]\n",
    "rating = [value for value in ratings.values()]\n",
    "predicted_relevance = [value for value in relevance.values()]\n",
    "our_truths = pd.DataFrame()\n",
    "our_truths['doc_id'] = doc_id\n",
    "our_truths['query_id'] = query_id\n",
    "our_truths['rating'] = rating\n",
    "our_truths['predicted_relevance'] = predicted_relevance\n",
    "our_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = our_truths.to_dict()\n",
    "#imprimir y tenerlo por ahí\n",
    "two = pd.DataFrame(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'South Carolina #HurricaneIan https://t.co/yTA4dFUC2V'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['Document'] == 'doc_254']['Text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "Top 10 results out of 605 for the searched query 'Floodings in South Carolina':\n",
      "\n",
      "doc_254 - score 4.74475387696339 Text:\n",
      "\tSouth Carolina #HurricaneIan https://t.co/yTA4dFUC2V\n",
      "doc_1289 - score 4.315205653041319 Text:\n",
      "\tFlooding in Garden City, South Carolina \n",
      "\n",
      "#GardenCity #SouthCarolina #HurricaneIan https://t.co/5W328kjWkH\n",
      "doc_2874 - score 4.10872348195652 Text:\n",
      "\tFrom .@ABCNews4 in Charleston, South Carolina - #HurricaneIan https://t.co/TLCRoQ3VvD\n",
      "doc_2834 - score 4.10872348195652 Text:\n",
      "\tfrom .@ABCNews4 in Charleston, South Carolina - #HurricaneIan https://t.co/nbxQROQSKW\n",
      "doc_174 - score 4.10872348195652 Text:\n",
      "\tSouth Carolina #HurricaneIan here we go\n",
      "doc_2484 - score 4.067471844340135 Text:\n",
      "\tFloods trap many in Florida as Ian heads to South Carolina\n",
      "https://t.co/zmUfHC9egM #HurricaneIan\n",
      "doc_493 - score 3.962766890072915 Text:\n",
      "\tJust south of Myrtle Beach in South Carolina. #HurricaneIan #Ian #ScWx https://t.co/ErHr5X5cQQ\n",
      "doc_2505 - score 3.674842282261912 Text:\n",
      "\t⚠️ #HurricaneIan about to make landfall on South Carolina! https://t.co/X61NAwpsx6\n",
      "doc_249 - score 3.674842282261912 Text:\n",
      "\t#HurricaneIan makes landfall in South Carolina... https://t.co/vKik1OyOgQ\n",
      "doc_1078 - score 3.674842282261912 Text:\n",
      "\tNow South Carolina is getting hammered by #HurricaneIan 😫 https://t.co/fnGkXXhKM8\n",
      "\n",
      "======================\n",
      "Top 10 results out of 131 for the searched query 'HuracaineIan disaster':\n",
      "\n",
      "doc_3964 - score 4.132642169823945 Text:\n",
      "\tDuke Energy donates $100,000 to the Florida Disaster Fund, managed by Volunteer Florida Foundation, to assist communities affected by #HurricaneIan. To contribute to the Florida Disaster Fund, visit https://t.co/zx6l40CRQv or text DISASTER to 20222. Info: https://t.co/oAmCDqYkVQ https://t.co/UVsnxWHWGu\n",
      "doc_865 - score 3.792112455030452 Text:\n",
      "\t#HurricaneIan Update: Orange County has been added to FEMA disaster declaration.\n",
      "\n",
      "Survivors can apply for disaster assistance at:\n",
      "\n",
      "📞1-800-621-3362 from 7AM to 11PM\n",
      "💻https://t.co/s81A48Kerf\n",
      "📱 FEMA App: https://t.co/RqJtEqwglw\n",
      "\n",
      "More info: https://t.co/6sgDgzn4yA https://t.co/9doNussSQ7\n",
      "doc_3933 - score 3.6962351566905367 Text:\n",
      "\tThank you 🙏🏻 #etg♥️\n",
      "#FortMyers #HurricaneIan #Disaster\n",
      "#Floridaintheheart https://t.co/yCeh8q6Vzg\n",
      "doc_259 - score 3.6962351566905367 Text:\n",
      "\tIronic that @MikeFOX29 segment on @DA_LarryKrasner #Philly disaster was on  @FoxNews\n",
      "@FaulknerFocus right before on my update on the #HurricaneIan disaster in my new new homepage in @CapeCoral #ImpeachKrasner #PrayForFlorida\n",
      "doc_1635 - score 3.6962351566905367 Text:\n",
      "\tDid you know there is a #DisasterDistressHelpline (DDH) dedicated to disaster crisis counseling? This is for US residents experiencing mental health concerns related to a natural disaster. 1-800-985-5990\n",
      "\n",
      "#HurricaneIan #MentalHealthMatters https://t.co/oGfP2kCJ5i\n",
      "doc_1252 - score 3.6069700858223395 Text:\n",
      "\tText DISASTER to 20222 or visit this page to donate to the Florida Disaster Fund: https://t.co/e2ldBVQiOG\n",
      "\n",
      "Many thanks to @CoasterCreature for sharing. ♥️\n",
      "\n",
      "#Florida #HurricaneIan #Donate\n",
      "doc_27 - score 3.5243172424258606 Text:\n",
      "\tIn the aftermath of a Disaster some just can’t resist taking advantage of the vulnerability. \n",
      "\n",
      "Disaster related scams can happen to anyone, awareness helps reduce the chances it’s you.\n",
      "\n",
      "#HurricaneIan #PuertoRico #Florida #Georgia #SouthCarolina  https://t.co/4ncfVvmu6F\n",
      "doc_2538 - score 3.44662356963317 Text:\n",
      "\t@bannerite It’s about politics for his campaign; do NOT, I highly recommend do NOT donate to #desantis Fl disaster fund.  Donate to well-established orgs like @RedCross  with a history of working with victims of disasters. \n",
      "#HurricaneIan\n",
      "doc_197 - score 3.373889067444269 Text:\n",
      "\tWhen natural disasters hit, @TeamRubicon leverages the unique experiences of military #veterans to deliver timely disaster relief and humanitarian aid.  If you are looking for an organization to support in the aftermath of #HurricaneIan, please check them out below 👇 https://t.co/tudaHaqAbg\n",
      "doc_2329 - score 3.241644518009903 Text:\n",
      "\tOur hearts are with all families being impacted by #HurricaneIan in Florida and the Carolinas. For resources on how to help children during natural disasters, please read “Understanding the Impacts of Natural Disasters on Children”: https://t.co/unXxBwax22\n",
      "\n",
      "======================\n",
      "Top 10 results out of 231 for the searched query 'Damage of HuracaineIan':\n",
      "\n",
      "doc_2687 - score 2.8749627271127562 Text:\n",
      "\tJust over Blind Pass Bridge on #Sanibel #Captiva Rd. Significant damage here. Structures missing and damages. #Ian #HurricaneIan #flwx https://t.co/0a9vCgoVD5\n",
      "doc_1555 - score 2.8749627271127562 Text:\n",
      "\tThe damage from #HurricaneIan is “catastrophic” and historic.\n",
      "https://t.co/OY323JCzyQ 02\n",
      "doc_1226 - score 2.638065798398665 Text:\n",
      "\tFRIDAY MORNING AFTER IAN🌀 The damage is no longer hidden under water in SOME LOCATIONS! #HurricaneIan damage, Border of Port Charlotte &amp; Engelwood.#flwx \n",
      "📸 @peaceluvorganix #TheWeatherlady #KindnessForSteve https://t.co/cWsU1RrFHg\n",
      "doc_3735 - score 2.5713666631296492 Text:\n",
      "\tSatellite imagery of the damage https://t.co/NggqAbpfnT\n",
      "\n",
      "#hurricaneian #sanibel\n",
      "doc_372 - score 2.5713666631296492 Text:\n",
      "\tNOAA68 is surveying the damage from #HurricaneIan over Southwest Florida.  \n",
      "\n",
      "#A9025B #N68RF as NOAA68 https://t.co/NW6nAj7Lem\n",
      "doc_3658 - score 2.5713666631296492 Text:\n",
      "\tWe can’t get into plantation . #venicefl #HurricaneIan #Damage https://t.co/h7k23cMVLk\n",
      "doc_3409 - score 2.5713666631296492 Text:\n",
      "\t#wellness check #HurricaneIan #Damage #venicefl https://t.co/7ZPtL5Hj8c\n",
      "doc_339 - score 2.5713666631296492 Text:\n",
      "\tas #Biden spends 3 of 5 minutes talking about Russia he hasn't a clue of the damage done in Florida. Drone footage shows #HurricaneIan damage in Fort Myers https://t.co/XHLKle54mp via @YouTube\n",
      "doc_3068 - score 2.5713666631296492 Text:\n",
      "\t#wellness check #HurricaneIan #venicefl #damage https://t.co/8i6n8QhzEV\n",
      "doc_3060 - score 2.5713666631296492 Text:\n",
      "\tWaiting for Trump to say Mar-a-lago was severely damaged by #HurricaneIan… 🤔🤡 https://t.co/SkvPewCFgI\n",
      "\n",
      "======================\n",
      "Top 10 results out of 1114 for the searched query 'Florida floodings':\n",
      "\n",
      "doc_1317 - score 3.794380721457354 Text:\n",
      "\thttps://t.co/Tzw965uBgX\n",
      "\n",
      "Here is the SERFC's Florida briefing for flooding from #hurricaneIan #flwx #flood https://t.co/cd4ljIyNmI\n",
      "doc_1672 - score 3.250375687450309 Text:\n",
      "\tEdgewater Florida Flooding. #HurricaneIan https://t.co/eK3lFQ0yLq\n",
      "doc_1493 - score 2.9694789323793103 Text:\n",
      "\tIt’s not the wind that’s so bad for us in the lowcountry ; like in Florida it’s the wind I worry about. Here it’s the FLOODING. The lowcountry floods during regular rain storms; hurricanes can flood out so many homes so fast here. #HurricaneIan\n",
      "doc_2901 - score 2.907136014855557 Text:\n",
      "\t9/30/2022  #HurricaneIan Florida Rain, Flood Reports\n",
      "https://t.co/fGv2hNZv1p https://t.co/vn0EcsA4oy\n",
      "doc_824 - score 2.8189040144223148 Text:\n",
      "\thttps://t.co/eo9loHhTbh\n",
      "\n",
      "Here is the Decision Support Briefing addressing potential flooding in the Carolinas and Virginia from #HurricaneIan #flood https://t.co/SxlCiVJgpR\n",
      "doc_1862 - score 2.8189040144223148 Text:\n",
      "\tThis is near where I live. Flood didn't affect me. Caused by flooding of #EconRiver #EconTrail #HurricaneIan #FloridaLife https://t.co/G1r0teVGAj\n",
      "doc_1147 - score 2.8189040144223148 Text:\n",
      "\tFlooding in Portsmouth.  @WAVY_News @WAVY_Weather #HurricaneIan https://t.co/MpSPxnSl1e\n",
      "doc_2488 - score 2.7080811513683023 Text:\n",
      "\tIf you are in a flood zone, you will be required by your mortgage company to carry a flood policy.  Here is what it covers. \n",
      "#HurricaneIan #floodinsurance https://t.co/FEiq7SI4cq\n",
      "doc_1374 - score 2.7080811513683023 Text:\n",
      "\tjust had an advert pop up for help #floods in pakistan. how about helping the floods for #miami and #Hurricane_Ian #hurricaneian\n",
      "doc_3998 - score 2.6536067112344326 Text:\n",
      "\tSo it really wasn't #HurricaneIan that flooded #Florida. Just #MAGATears over a flute https://t.co/9VPkyjZvWO\n",
      "\n",
      "======================\n",
      "Top 10 results out of 1333 for the searched query 'Storm and wind in Florida':\n",
      "\n",
      "doc_370 - score 2.8184075410327574 Text:\n",
      "\t#HurricaneIan Advisory 35\n",
      "Max Winds: 85mph\n",
      "SSHWS: C1\n",
      "MSLP: 977mb\n",
      "The center of #Ian is about to make landfall. Life-threatening storm surge, damaging winds and flash flooding lashing the Carolinas... https://t.co/n8to5AtP2d\n",
      "doc_2794 - score 2.77975276449882 Text:\n",
      "\tStorm chaser Reed Timmer (@ReedTimmerAccu) recorded a chaotic scene with flooding storm surge and howling winds in Pine Island, Florida, as he entered the eye of #HurricaneIan on Sept. 28. https://t.co/GGFQFnP47q https://t.co/bY8LFDl5Py\n",
      "doc_1417 - score 2.7583100467507595 Text:\n",
      "\tWind resiliency in #CapeCoral from #HurricaneIan has been better than I ever would of expected. Before/After pics show only 4 homes out of 23 on this block have obvious wind damage, despite Cat 3-4 wind gusts. https://t.co/MtfiO80gtm\n",
      "doc_3501 - score 2.750342242635723 Text:\n",
      "\t#HurricaneIan Advisory 34A\n",
      "Max Winds: 85mph\n",
      "SSHWS: C1\n",
      "MSLP: 980mb\n",
      "#Hurricane #Ian accelerating toward the South #Carolina coast. Life-threatening storm surge and damaging winds arriving soon... https://t.co/8t40sCKLXZ\n",
      "doc_557 - score 2.746573006641334 Text:\n",
      "\t2 PM Update: #HurricaneIan about to make landfall.\n",
      "Center of the storm now 55 miles ENE of Charleston, SC with 85 mph winds, still a Cat 1 Hurricane.\n",
      "Flash flooding, damaging winds, life threatening storm surge expected, it should weaken rapidly as it continues to move over land. https://t.co/8fAVEAGksS\n",
      "doc_3012 - score 2.6689002423135753 Text:\n",
      "\t11 A.M. ADVISORY: Life-threatening storm surge, damaging winds to arrive soon in the Carolinas https://t.co/HenfcuQkGo #HurricaneIan https://t.co/emI2t0UuLG\n",
      "doc_2934 - score 2.6689002423135753 Text:\n",
      "\t#HurricaneIan’s tropical storm winds extend 500 miles! Here’s how that looks compared to #Texas. https://t.co/daOJqyvyR0\n",
      "doc_2813 - score 2.6689002423135753 Text:\n",
      "\t9/30/2022 8 AM EDT. National Hurricane Center - \n",
      "#HurricaneIan Storm Force Wind Probabilities\n",
      "https://t.co/ooadBh9rN8 https://t.co/TA7RwVEUME\n",
      "doc_772 - score 2.654413701656481 Text:\n",
      "\tThe wind here is wild #HurricaneIan\n",
      "doc_2950 - score 2.6469033472308743 Text:\n",
      "\t9/30/2022  #HurricaneIan Florida Most Significant Wind Gusts\n",
      "https://t.co/fGv2hNZv1p https://t.co/VGDKxYqwB8\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    ranked_docs = search_tf_idf(query, new_index)\n",
    "    top = 10\n",
    "\n",
    "    print(\"\\n======================\\nTop {} results out of {} for the searched query '{}':\\n\".format(top, len(ranked_docs),query))\n",
    "    for doc in ranked_docs[:top]:\n",
    "        print(\"{} - score {} Text:\".format(doc[1], doc[0]))\n",
    "        print(\"\\t{}\".format(data.loc[data['Document'] == doc[1]]['Text'].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the ranking considering only the subset of documents in the ground truth file provided (\"evaluation_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>query_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc_12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc_9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc_18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc_45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc_501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc  query_id  label\n",
       "0   doc_12         1      1\n",
       "1    doc_9         1      1\n",
       "2   doc_18         1      1\n",
       "3   doc_45         1      1\n",
       "4  doc_501         1      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = pd.read_csv('evaluation_gt.csv')\n",
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(doc_score, k=10): #binary relevance, predicted relevance, k for a given query\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_score: Ordered ground truth (true relevance labels).\n",
    "    k : number of doc to consider.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    precision @k : float\n",
    "\n",
    "    \"\"\"\n",
    "    doc_score = doc_score[:k]\n",
    "    relevant = sum(doc_score == 1) #get number of relevant documents\n",
    "    return float(relevant) / k #calculae precision at k, which is the number of relevant documents trieved at k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(doc_score, k=10): #binary relevance, predicted relevance, k for a given query\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_score: Ordered ground truth (true relevance labels).\n",
    "    k : number of doc to consider.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    precision @k : float\n",
    "\n",
    "    \"\"\"\n",
    "    total_relevant = sum(doc_score == 1)\n",
    "    doc_score = doc_score[:k]\n",
    "    relevant = sum(doc_score == 1) #get number of relevant documents\n",
    "    return float(relevant) / total_relevant #calculae precision at k, which is the number of relevant documents trieved at k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_precision_at_k(doc_score, k=10): #binary relevance, predicted relevance, k for a given query\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_score: Ordered ground truth (true relevance labels).\n",
    "    k : number of doc to consider.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    average precision @k : float\n",
    "    \"\"\"\n",
    "    gtp = np.sum(doc_score == 1) #Total number of gt positives\n",
    "    doc_score = doc_score[:k] #same as for precision\n",
    "    ## if all documents are not relevant\n",
    "    if gtp == 0:\n",
    "        return 0\n",
    "    n_relevant_at_i = 0\n",
    "    prec_at_i = 0\n",
    "    for i in range(len(doc_score)):\n",
    "        if doc_score[i] == 1: #only add the P@k when the doc is relevant\n",
    "            n_relevant_at_i += 1\n",
    "            prec_at_i += n_relevant_at_i / (i + 1) #calculate P@K (#docs relevant at k/k)\n",
    "    return prec_at_i / gtp #return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg(queries, doc_score):\n",
    "\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for query in queries:\n",
    "        ncdg_score = 0\n",
    "        for i, score in enumerate(doc_score):\n",
    "            ncdg_score += score/math.log(2,i+1)\n",
    "\n",
    "        ndcg_scores.append(ncdg_score)\n",
    "\n",
    "    for i, ndcg in enumerate(ndcg_scores):\n",
    "        top = max(ndcg_scores)\n",
    "        ndcg_scores[i] = ndcg/top\n",
    "\n",
    "    return ndcg_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_at_k(search_res, k=10): #receives all the search esults dataframe containing all the queries and the results and relevances\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    search_res: search results dataset containing:\n",
    "        query_id: query id.\n",
    "        doc: document id.\n",
    "        predicted_relevance: relevance predicted through LightGBM.\n",
    "        label: actual score of the document for the query (ground truth).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mean average precision @ k : float\n",
    "    \"\"\"\n",
    "    avp = []\n",
    "    for q in search_res[\"query_id\"].unique():  # loop over all query ids\n",
    "        curr_data = search_res[search_res[\"query_id\"] == q]  # select data for current query (get a slice of the dataframe keeping only the data related to the current query)\n",
    "        avp.append(avg_precision_at_k(np.array(curr_data[\"label\"]), k))  #append average precision for current query\n",
    "    return np.sum(avp) / len(avp), avp  # return mean average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rr_at_k(doc_score, k=10):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_score: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Reciprocal Rank for qurrent query\n",
    "    \"\"\"\n",
    "\n",
    "    doc_score = doc_score[:k]\n",
    "    if np.sum(doc_score) == 0:  # if there are not relevant doument return 0\n",
    "        return 0\n",
    "    return 1 / (np.argmax(doc_score == 1) + 1)  # hint: to get the position of the first relevant document use \"np.argmax\" (+1 because the idex starts from 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "Results for the subset of docs in the ground truth query 'Landfall in South Carolina':\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_relevance</th>\n",
       "      <th>doc</th>\n",
       "      <th>query_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.835268</td>\n",
       "      <td>doc_82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.672444</td>\n",
       "      <td>doc_501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.918111</td>\n",
       "      <td>doc_165</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.600135</td>\n",
       "      <td>doc_12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.426312</td>\n",
       "      <td>doc_100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.247656</td>\n",
       "      <td>doc_18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.500909</td>\n",
       "      <td>doc_9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.500909</td>\n",
       "      <td>doc_122</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.203699</td>\n",
       "      <td>doc_45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.162720</td>\n",
       "      <td>doc_52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_125</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_306</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_441</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_494</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_525</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1076</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1195</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted_relevance       doc  query_id  label\n",
       "0              3.835268    doc_82         1      1\n",
       "1              3.672444   doc_501         1      1\n",
       "2              2.918111   doc_165         1      1\n",
       "3              2.600135    doc_12         1      1\n",
       "4              2.426312   doc_100         1      1\n",
       "5              2.247656    doc_18         1      1\n",
       "6              1.500909     doc_9         1      1\n",
       "7              1.500909   doc_122         1      1\n",
       "8              1.203699    doc_45         1      1\n",
       "9              1.162720    doc_52         1      1\n",
       "10             0.000000   doc_125         1      0\n",
       "11             0.000000   doc_306         1      0\n",
       "12             0.000000   doc_441         1      0\n",
       "13             0.000000   doc_494         1      0\n",
       "14             0.000000   doc_525         1      0\n",
       "15             0.000000  doc_1002         1      0\n",
       "16             0.000000  doc_1076         1      0\n",
       "17             0.000000  doc_1096         1      0\n",
       "18             0.000000  doc_1195         1      0\n",
       "19             0.000000  doc_1233         1      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@K 1.0\n",
      "AP@K 1.0\n",
      "R@K 1.0\n",
      "RR@K 1.0\n",
      "\n",
      "======================\n",
      "Results for the subset of docs in the ground truth query 'Help and recovery during the hurricanee disaster':\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_relevance</th>\n",
       "      <th>doc</th>\n",
       "      <th>query_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.105629</td>\n",
       "      <td>doc_402</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476477</td>\n",
       "      <td>doc_268</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.262324</td>\n",
       "      <td>doc_504</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.222461</td>\n",
       "      <td>doc_321</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.987710</td>\n",
       "      <td>doc_1233</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.758298</td>\n",
       "      <td>doc_373</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.683397</td>\n",
       "      <td>doc_158</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.596469</td>\n",
       "      <td>doc_358</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.596469</td>\n",
       "      <td>doc_175</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.516648</td>\n",
       "      <td>doc_453</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.516648</td>\n",
       "      <td>doc_303</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_306</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_441</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_494</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_525</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1002</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1076</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1096</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1195</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted_relevance       doc  query_id  label\n",
       "0              3.105629   doc_402         2      1\n",
       "1              2.476477   doc_268         2      1\n",
       "2              2.262324   doc_504         2      1\n",
       "3              1.222461   doc_321         2      1\n",
       "4              0.987710  doc_1233         2      0\n",
       "5              0.758298   doc_373         2      1\n",
       "6              0.683397   doc_158         2      1\n",
       "7              0.596469   doc_358         2      1\n",
       "8              0.596469   doc_175         2      1\n",
       "9              0.516648   doc_453         2      1\n",
       "10             0.516648   doc_303         2      1\n",
       "11             0.000000   doc_125         2      0\n",
       "12             0.000000   doc_306         2      0\n",
       "13             0.000000   doc_441         2      0\n",
       "14             0.000000   doc_494         2      0\n",
       "15             0.000000   doc_525         2      0\n",
       "16             0.000000  doc_1002         2      0\n",
       "17             0.000000  doc_1076         2      0\n",
       "18             0.000000  doc_1096         2      0\n",
       "19             0.000000  doc_1195         2      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@K 0.9\n",
      "AP@K 0.8354365079365079\n",
      "R@K 0.9\n",
      "RR@K 1.0\n",
      "\n",
      "======================\n",
      "Results for the subset of docs in the ground truth query 'Floodings in South Carolina':\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_relevance</th>\n",
       "      <th>doc</th>\n",
       "      <th>query_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.385289</td>\n",
       "      <td>doc_66</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.116143</td>\n",
       "      <td>doc_148</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.728733</td>\n",
       "      <td>doc_65</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.728733</td>\n",
       "      <td>doc_65</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.191773</td>\n",
       "      <td>doc_30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.191773</td>\n",
       "      <td>doc_30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.108991</td>\n",
       "      <td>doc_198</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.764199</td>\n",
       "      <td>doc_370</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.914432</td>\n",
       "      <td>doc_1195</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.849855</td>\n",
       "      <td>doc_150</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.740235</td>\n",
       "      <td>doc_112</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_125</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_306</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_441</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_494</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_525</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1002</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1076</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1096</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1233</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted_relevance       doc  query_id  label\n",
       "0              3.385289    doc_66         3      1\n",
       "1              3.116143   doc_148         3      1\n",
       "2              2.728733    doc_65         3      1\n",
       "3              2.728733    doc_65         3      1\n",
       "4              2.191773    doc_30         3      1\n",
       "5              2.191773    doc_30         3      1\n",
       "6              2.108991   doc_198         3      1\n",
       "7              1.764199   doc_370         3      1\n",
       "8              0.914432  doc_1195         3      0\n",
       "9              0.849855   doc_150         3      1\n",
       "10             0.740235   doc_112         3      1\n",
       "11             0.000000   doc_125         3      0\n",
       "12             0.000000   doc_306         3      0\n",
       "13             0.000000   doc_441         3      0\n",
       "14             0.000000   doc_494         3      0\n",
       "15             0.000000   doc_525         3      0\n",
       "16             0.000000  doc_1002         3      0\n",
       "17             0.000000  doc_1076         3      0\n",
       "18             0.000000  doc_1096         3      0\n",
       "19             0.000000  doc_1233         3      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@K 0.9\n",
      "AP@K 0.89\n",
      "R@K 0.9\n",
      "RR@K 1.0\n",
      "MAP@K (0.908478835978836, [1.0, 0.8354365079365079, 0.89])\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "ground_truth_queries = {\n",
    "    1:\"Landfall in South Carolina\",\n",
    "    2:\"Help and recovery during the hurricanee disaster\",\n",
    "    3:\"Floodings in South Carolina\"}\n",
    "\n",
    "final = pd.DataFrame()\n",
    "for query_id, query in ground_truth_queries.items():\n",
    "    ranking = search_tf_idf_subset(query, new_index, set(ground_truth[ground_truth['query_id']==query_id]['doc']))\n",
    "    print(\"\\n======================\\nResults for the subset of docs in the ground truth query '{}':\\n\".format(query))\n",
    "    rankingdf = pd.DataFrame(ranking, columns=['predicted_relevance', 'doc']).merge(ground_truth[ground_truth['query_id']==query_id], how='outer', on='doc').fillna(0)\n",
    "    display(rankingdf)\n",
    "    print(\"P@K\",precision_at_k(rankingdf['label']))\n",
    "    print(\"AP@K\",avg_precision_at_k(rankingdf['label']))\n",
    "    print(\"R@K\", recall_at_k(rankingdf['label']))\n",
    "    print(\"RR@K\",rr_at_k(rankingdf['label']))\n",
    "    if final.empty:\n",
    "        final = rankingdf\n",
    "    else:\n",
    "        final = pd.concat([final, rankingdf])\n",
    "\n",
    "print(\"MAP@K\",map_at_k(final))\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "vectors = #falta meter la data\n",
    "\n",
    "plot = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3).fit_transform(vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ced987a247890006fadb174404bf884c2606133e9ca5a8bdda00b49ca7b4dc36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
