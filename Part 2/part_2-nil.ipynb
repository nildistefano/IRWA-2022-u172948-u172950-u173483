{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------- #\n",
    "# SON LOS IMPORTS DEL LAB ANTERIOR, LOS DESCOMENTAMOS A MEDIDA QUE LOS VAYAMOS USANDO #\n",
    "# ----------------------------------------------------------------------------------- #\n",
    "\n",
    "# from collections import defaultdict\n",
    "from array import array\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "# # nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "from numpy import linalg as la\n",
    "# import json\n",
    "# import random\n",
    "# import re\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the processed tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Url</th>\n",
       "      <th>Clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc_1</td>\n",
       "      <td>1575918182698979328</td>\n",
       "      <td>So this will keep spinning over us until 7 pm…...</td>\n",
       "      <td>suzjdean</td>\n",
       "      <td>Fri Sep 30 18:39:08 +0000 2022</td>\n",
       "      <td>['HurricaneIan']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/suzjdean/status/1575918182...</td>\n",
       "      <td>['keep', 'spin', 'us', 'away', 'alreadi', 'hur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc_2</td>\n",
       "      <td>1575918151862304768</td>\n",
       "      <td>Our hearts go out to all those affected by #Hu...</td>\n",
       "      <td>lytx</td>\n",
       "      <td>Fri Sep 30 18:39:01 +0000 2022</td>\n",
       "      <td>['HurricaneIan']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/lytx/status/15759181518623...</td>\n",
       "      <td>['heart', 'go', 'affect', 'hurricaneian', 'wis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Document                   Id  \\\n",
       "0    doc_1  1575918182698979328   \n",
       "1    doc_2  1575918151862304768   \n",
       "\n",
       "                                                Text  Username  \\\n",
       "0  So this will keep spinning over us until 7 pm…...  suzjdean   \n",
       "1  Our hearts go out to all those affected by #Hu...      lytx   \n",
       "\n",
       "                             Date          Hashtags Mentions  Likes  Retweets  \\\n",
       "0  Fri Sep 30 18:39:08 +0000 2022  ['HurricaneIan']      NaN      0         0   \n",
       "1  Fri Sep 30 18:39:01 +0000 2022  ['HurricaneIan']      NaN      0         0   \n",
       "\n",
       "                                                 Url  \\\n",
       "0  https://twitter.com/suzjdean/status/1575918182...   \n",
       "1  https://twitter.com/lytx/status/15759181518623...   \n",
       "\n",
       "                                          Clean_text  \n",
       "0  ['keep', 'spin', 'us', 'away', 'alreadi', 'hur...  \n",
       "1  ['heart', 'go', 'affect', 'hurricaneian', 'wis...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder = '../output/'\n",
    "data = pd.read_csv(output_folder + \"lab1_tweets_df.csv\", sep='|')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_terms(line):\n",
    "    \"\"\"\n",
    "    Preprocess the article text (title + body) removing stop words, stemming,\n",
    "    transforming in lowercase and return the tokens of the text.\n",
    "    \n",
    "    Argument:\n",
    "    line -- string (text) to be preprocessed\n",
    "    \n",
    "    Returns:\n",
    "    line - a list of tokens corresponding to the input text after the preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    ## START CODE\n",
    "    line=  line.lower() ## Transform in lowercase\n",
    "    line=  line.split() ## Tokenize the text to get a list of terms\n",
    "    line= [x for x in line if x not in stop_words]  ##eliminate the stopwords (HINT: use List Comprehension)\n",
    "    line= [stemmer.stem(x) for x in line] ## perform stemming (HINT: use List Comprehension)\n",
    "    ## END CODE\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_tfidf(dataframe):\n",
    "    \"\"\"\n",
    "    Implement the inverted index and compute tf, df and idf\n",
    "    \n",
    "    Argument:\n",
    "    dataframe -- DataFrame containing tweet information\n",
    "    \n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
    "    list of document these keys appears in (and the positions) as values.\n",
    "    tf - normalized term frequency for each term in each document\n",
    "    df - number of documents each term appear in\n",
    "    idf - inverse document frequency of each term\n",
    "    \"\"\"\n",
    "    num_documents = dataframe.shape[0]\n",
    "    index = defaultdict(list)\n",
    "    tf = defaultdict(list)  # term frequencies of terms in documents (documents in the same order as in the main index)\n",
    "    df = defaultdict(int)   # document frequencies of terms in the corpus\n",
    "    idf = defaultdict(float)\n",
    "    for row in dataframe.iterrows():\n",
    "        doc_id = row[1]['Document']\n",
    "        terms = row[1]['Clean_text']  \n",
    "        terms = eval(terms)\n",
    "        \n",
    "        ## ===============================================================        \n",
    "        ## create the index for the **current page** and store it in current_page_index\n",
    "        ## current_page_index ==> { ‘term1’: [current_doc, [list of positions]], ...,‘term_n’: [current_doc, [list of positions]]}\n",
    "\n",
    "        ## Example: if the curr_doc has id 1 and his text is \n",
    "        ##\"web retrieval information retrieval\":\n",
    "\n",
    "        ## current_page_index ==> { ‘web’: [1, [0]], ‘retrieval’: [1, [1,4]], ‘information’: [1, [2]]}\n",
    "\n",
    "        ## the term ‘web’ appears in document 1 in positions 0, \n",
    "        ## the term ‘retrieval’ appears in document 1 in positions 1 and 4\n",
    "        ## ===============================================================\n",
    "\n",
    "        current_page_index = {}\n",
    "\n",
    "        for position, term in enumerate(terms):  ## terms contains page_title + page_text\n",
    "            try:\n",
    "                # if the term is already in the dict append the position to the corresponding list\n",
    "                current_page_index[term][1].append(position) \n",
    "            except:\n",
    "                # Add the new term as dict key and initialize the array of positions and add the position\n",
    "                current_page_index[term]=[doc_id, [position]]\n",
    "                \n",
    "        #normalize term frequencies\n",
    "        # Compute the denominator to normalize term frequencies (formula 2 above)\n",
    "        # norm is the same for all terms of a document.\n",
    "        norm = 0\n",
    "        for term, posting in current_page_index.items():\n",
    "            # posting will contain the list of positions for current term in current document. \n",
    "            # posting ==> [current_doc, [list of positions]] \n",
    "            # you can use it to infer the frequency of current term.\n",
    "            norm += len(posting[1]) ** 2\n",
    "        norm = math.sqrt(norm)\n",
    "\n",
    "        # calculate the tf(dividing the term frequency by the above computed norm) and df weights\n",
    "        for term, posting in current_page_index.items():\n",
    "            # append the tf for current term (tf = term frequency in current doc/norm)\n",
    "            tf[term].append(np.round(len(posting[1])/norm,4)) ## SEE formula (1) above\n",
    "            #increment the document frequency of current term (number of documents containing the current term)\n",
    "            df[term] = df[term]+1 # increment DF for current term\n",
    "\n",
    "        #merge the current page index with the main index\n",
    "        for term_page, posting_page in current_page_index.items():\n",
    "            index[term_page].append(posting_page)\n",
    "\n",
    "        # Compute IDF following the formula (3) above. HINT: use np.log\n",
    "        for term in df:\n",
    "            idf[term] = np.round(np.log(float(num_documents/df[term])), 4)\n",
    "\n",
    "    return index, tf, df, idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to create the index: 234.99 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "new_index, tf, df, idf = create_index_tfidf(data)\n",
    "print(\"Total time to create the index: {} seconds\" .format(np.round(time.time() - start_time, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"Floodings in South Carolina\", \n",
    "    \"HuracaineIan disaster\", \n",
    "    \"Damage of HuracaineIan\", \n",
    "    \"Florida floodings\", \n",
    "    \"Storm and wind in Florida\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_documents(terms, docs, index, idf, tf):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "    \n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "    \n",
    "    Returns:\n",
    "    Print the list of ranked documents\n",
    "    \"\"\"\n",
    "\n",
    "    # I'm interested only on the element of the docVector corresponding to the query terms \n",
    "    # The remaining elements would became 0 when multiplied to the query_vector\n",
    "    doc_vectors = defaultdict(lambda: [0] * len(terms)) # I call doc_vectors[k] for a nonexistent key k, the key-value pair (k,[0]*len(terms)) will be automatically added to the dictionary\n",
    "    query_vector = [0] * len(terms)\n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = collections.Counter(terms)  # get the frequency of each term in the query. \n",
    "    # Example: collections.Counter([\"hello\",\"hello\",\"world\"]) --> Counter({'hello': 2, 'world': 1})\n",
    "    # HINT: use when computing tf for query_vector\n",
    "\n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "\n",
    "    for termIndex, term in enumerate(terms):  #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        ## Compute tf*idf(normalize TF as done with documents)\n",
    "        query_vector[termIndex]=query_terms_count[term]/query_norm *idf[term]\n",
    "\n",
    "        # Generate doc_vectors for matching docs\n",
    "        for doc_index, (doc, postings) in enumerate(index[term]):\n",
    "            # Example of [doc_index, (doc, postings)]\n",
    "            # 0 (26, array('I', [1, 4, 12, 15, 22, 28, 32, 43, 51, 68, 333, 337]))\n",
    "            # 1 (33, array('I', [26, 33, 57, 71, 87, 104, 109]))\n",
    "            # term is in doc 26 in positions 1,4, .....\n",
    "            # term is in doc 33 in positions 26,33, .....\n",
    "\n",
    "            #tf[term][0] will contain the tf of the term \"term\" in the doc 26            \n",
    "            if doc in docs:\n",
    "                doc_vectors[doc][termIndex] = tf[term][doc_index] * idf[term]  # TODO: check if multiply for idf\n",
    "    \n",
    "    # Calculate the score of each doc \n",
    "    # compute the cosine similarity between queyVector and each docVector:\n",
    "    # HINT: you can use the dot product because in case of normalized vectors it corresponds to the cosine similarity\n",
    "    # see np.dot\n",
    "    \n",
    "    doc_scores=[[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items() ]\n",
    "    doc_scores.sort(reverse=True)\n",
    "    #print document titles instead if document id's\n",
    "    #result_docs=[ title_index[x] for x in result_docs ]\n",
    "    if len(doc_scores) == 0:\n",
    "        print(\"No results found for query\")\n",
    "    #print ('\\n'.join(result_docs), '\\n')\n",
    "    return doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tf_idf(query, index):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain any of the query terms. \n",
    "    So, we will get the list of documents for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = build_terms(query)\n",
    "    docs = set()\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain \"term\"                        \n",
    "            term_docs=[posting[0] for posting in index[term]]\n",
    "            \n",
    "            # docs = docs Union term_docs\n",
    "            docs = docs.union(term_docs)\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    ranked_docs = rank_documents(query, docs, index, idf, tf)\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tf_idf_subset(query, index, subset):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain any of the query terms. \n",
    "    So, we will get the list of documents for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = build_terms(query)\n",
    "    docs = set()\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain \"term\" and are in the subset.                       \n",
    "            term_docs=[posting[0] for posting in index[term] if posting[0] in subset]\n",
    "            \n",
    "            # docs = docs Union term_docs\n",
    "            docs = docs.union(term_docs)\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    ranked_docs = rank_documents(query, docs, index, idf, tf)\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "Top 10 results out of 605 for the searched query 'Floodings in South Carolina':\n",
      "\n",
      "doc_254 - score 4.74475387696339 by: \n",
      "doc_1289 - score 4.315205653041319 by: \n",
      "doc_2874 - score 4.10872348195652 by: \n",
      "doc_2834 - score 4.10872348195652 by: \n",
      "doc_174 - score 4.10872348195652 by: \n",
      "doc_2484 - score 4.067471844340135 by: \n",
      "doc_493 - score 3.962766890072915 by: \n",
      "doc_2505 - score 3.674842282261912 by: \n",
      "doc_249 - score 3.674842282261912 by: \n",
      "doc_1078 - score 3.674842282261912 by: \n",
      "\n",
      "======================\n",
      "Top 10 results out of 131 for the searched query 'HuracaineIan disaster':\n",
      "\n",
      "doc_3964 - score 4.132642169823945 by: \n",
      "doc_865 - score 3.792112455030452 by: \n",
      "doc_3933 - score 3.6962351566905367 by: \n",
      "doc_259 - score 3.6962351566905367 by: \n",
      "doc_1635 - score 3.6962351566905367 by: \n",
      "doc_1252 - score 3.6069700858223395 by: \n",
      "doc_27 - score 3.5243172424258606 by: \n",
      "doc_2538 - score 3.44662356963317 by: \n",
      "doc_197 - score 3.373889067444269 by: \n",
      "doc_2329 - score 3.241644518009903 by: \n",
      "\n",
      "======================\n",
      "Top 10 results out of 231 for the searched query 'Damage of HuracaineIan':\n",
      "\n",
      "doc_2687 - score 2.8749627271127562 by: \n",
      "doc_1555 - score 2.8749627271127562 by: \n",
      "doc_1226 - score 2.638065798398665 by: \n",
      "doc_3735 - score 2.5713666631296492 by: \n",
      "doc_372 - score 2.5713666631296492 by: \n",
      "doc_3658 - score 2.5713666631296492 by: \n",
      "doc_3409 - score 2.5713666631296492 by: \n",
      "doc_339 - score 2.5713666631296492 by: \n",
      "doc_3068 - score 2.5713666631296492 by: \n",
      "doc_3060 - score 2.5713666631296492 by: \n",
      "\n",
      "======================\n",
      "Top 10 results out of 1114 for the searched query 'Florida floodings':\n",
      "\n",
      "doc_1317 - score 3.794380721457354 by: \n",
      "doc_1672 - score 3.250375687450309 by: \n",
      "doc_1493 - score 2.9694789323793103 by: \n",
      "doc_2901 - score 2.907136014855557 by: \n",
      "doc_824 - score 2.8189040144223148 by: \n",
      "doc_1862 - score 2.8189040144223148 by: \n",
      "doc_1147 - score 2.8189040144223148 by: \n",
      "doc_2488 - score 2.7080811513683023 by: \n",
      "doc_1374 - score 2.7080811513683023 by: \n",
      "doc_3998 - score 2.6536067112344326 by: \n",
      "\n",
      "======================\n",
      "Top 10 results out of 1333 for the searched query 'Storm and wind in Florida':\n",
      "\n",
      "doc_370 - score 2.8184075410327574 by: \n",
      "doc_2794 - score 2.77975276449882 by: \n",
      "doc_1417 - score 2.7583100467507595 by: \n",
      "doc_3501 - score 2.750342242635723 by: \n",
      "doc_557 - score 2.746573006641334 by: \n",
      "doc_3012 - score 2.6689002423135753 by: \n",
      "doc_2934 - score 2.6689002423135753 by: \n",
      "doc_2813 - score 2.6689002423135753 by: \n",
      "doc_772 - score 2.654413701656481 by: \n",
      "doc_2950 - score 2.6469033472308743 by: \n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    ranked_docs = search_tf_idf(query, new_index)\n",
    "    top = 10\n",
    "\n",
    "    print(\"\\n======================\\nTop {} results out of {} for the searched query '{}':\\n\".format(top, len(ranked_docs),query))\n",
    "    for doc in ranked_docs[:top]:\n",
    "        print(\"{} - score {} by: \".format(doc[1], doc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the ranking considering only the subset of documents in the ground truth file provided (\"evaluation_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>query_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc_12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc_9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc_18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc_45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc_501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc  query_id  label\n",
       "0   doc_12         1      1\n",
       "1    doc_9         1      1\n",
       "2   doc_18         1      1\n",
       "3   doc_45         1      1\n",
       "4  doc_501         1      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = pd.read_csv('evaluation_gt.csv')\n",
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "Results for the subset of docs in the ground truth query 'Landfall in South Carolina':\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_relevance</th>\n",
       "      <th>doc</th>\n",
       "      <th>query_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.835268</td>\n",
       "      <td>doc_82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.672444</td>\n",
       "      <td>doc_501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.918111</td>\n",
       "      <td>doc_165</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.600135</td>\n",
       "      <td>doc_12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.426312</td>\n",
       "      <td>doc_100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.247656</td>\n",
       "      <td>doc_18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.500909</td>\n",
       "      <td>doc_9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.500909</td>\n",
       "      <td>doc_122</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.203699</td>\n",
       "      <td>doc_45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.162720</td>\n",
       "      <td>doc_52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_125</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_306</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_441</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_494</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_525</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1076</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1195</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted_relevance       doc  query_id  label\n",
       "0              3.835268    doc_82         1      1\n",
       "1              3.672444   doc_501         1      1\n",
       "2              2.918111   doc_165         1      1\n",
       "3              2.600135    doc_12         1      1\n",
       "4              2.426312   doc_100         1      1\n",
       "5              2.247656    doc_18         1      1\n",
       "6              1.500909     doc_9         1      1\n",
       "7              1.500909   doc_122         1      1\n",
       "8              1.203699    doc_45         1      1\n",
       "9              1.162720    doc_52         1      1\n",
       "10             0.000000   doc_125         1      0\n",
       "11             0.000000   doc_306         1      0\n",
       "12             0.000000   doc_441         1      0\n",
       "13             0.000000   doc_494         1      0\n",
       "14             0.000000   doc_525         1      0\n",
       "15             0.000000  doc_1002         1      0\n",
       "16             0.000000  doc_1076         1      0\n",
       "17             0.000000  doc_1096         1      0\n",
       "18             0.000000  doc_1195         1      0\n",
       "19             0.000000  doc_1233         1      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@K 1.0\n",
      "AP@K 1.0\n",
      "R@K 1.0\n",
      "RR@K 1.0\n",
      "\n",
      "======================\n",
      "Results for the subset of docs in the ground truth query 'Help and recovery during the hurricanee disaster':\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_relevance</th>\n",
       "      <th>doc</th>\n",
       "      <th>query_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.105629</td>\n",
       "      <td>doc_402</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476477</td>\n",
       "      <td>doc_268</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.262324</td>\n",
       "      <td>doc_504</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.222461</td>\n",
       "      <td>doc_321</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.987710</td>\n",
       "      <td>doc_1233</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.758298</td>\n",
       "      <td>doc_373</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.683397</td>\n",
       "      <td>doc_158</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.596469</td>\n",
       "      <td>doc_358</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.596469</td>\n",
       "      <td>doc_175</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.516648</td>\n",
       "      <td>doc_453</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.516648</td>\n",
       "      <td>doc_303</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_306</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_441</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_494</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_525</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1002</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1076</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1096</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1195</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted_relevance       doc  query_id  label\n",
       "0              3.105629   doc_402         2      1\n",
       "1              2.476477   doc_268         2      1\n",
       "2              2.262324   doc_504         2      1\n",
       "3              1.222461   doc_321         2      1\n",
       "4              0.987710  doc_1233         2      0\n",
       "5              0.758298   doc_373         2      1\n",
       "6              0.683397   doc_158         2      1\n",
       "7              0.596469   doc_358         2      1\n",
       "8              0.596469   doc_175         2      1\n",
       "9              0.516648   doc_453         2      1\n",
       "10             0.516648   doc_303         2      1\n",
       "11             0.000000   doc_125         2      0\n",
       "12             0.000000   doc_306         2      0\n",
       "13             0.000000   doc_441         2      0\n",
       "14             0.000000   doc_494         2      0\n",
       "15             0.000000   doc_525         2      0\n",
       "16             0.000000  doc_1002         2      0\n",
       "17             0.000000  doc_1076         2      0\n",
       "18             0.000000  doc_1096         2      0\n",
       "19             0.000000  doc_1195         2      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@K 0.9\n",
      "AP@K 0.8354365079365079\n",
      "R@K 1.0\n",
      "RR@K 1.0\n",
      "\n",
      "======================\n",
      "Results for the subset of docs in the ground truth query 'Floodings in South Carolina':\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_relevance</th>\n",
       "      <th>doc</th>\n",
       "      <th>query_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.385289</td>\n",
       "      <td>doc_66</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.116143</td>\n",
       "      <td>doc_148</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.728733</td>\n",
       "      <td>doc_65</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.728733</td>\n",
       "      <td>doc_65</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.191773</td>\n",
       "      <td>doc_30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.191773</td>\n",
       "      <td>doc_30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.108991</td>\n",
       "      <td>doc_198</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.764199</td>\n",
       "      <td>doc_370</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.914432</td>\n",
       "      <td>doc_1195</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.849855</td>\n",
       "      <td>doc_150</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.740235</td>\n",
       "      <td>doc_112</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_125</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_306</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_441</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_494</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_525</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1002</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1076</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1096</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>doc_1233</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted_relevance       doc  query_id  label\n",
       "0              3.385289    doc_66         3      1\n",
       "1              3.116143   doc_148         3      1\n",
       "2              2.728733    doc_65         3      1\n",
       "3              2.728733    doc_65         3      1\n",
       "4              2.191773    doc_30         3      1\n",
       "5              2.191773    doc_30         3      1\n",
       "6              2.108991   doc_198         3      1\n",
       "7              1.764199   doc_370         3      1\n",
       "8              0.914432  doc_1195         3      0\n",
       "9              0.849855   doc_150         3      1\n",
       "10             0.740235   doc_112         3      1\n",
       "11             0.000000   doc_125         3      0\n",
       "12             0.000000   doc_306         3      0\n",
       "13             0.000000   doc_441         3      0\n",
       "14             0.000000   doc_494         3      0\n",
       "15             0.000000   doc_525         3      0\n",
       "16             0.000000  doc_1002         3      0\n",
       "17             0.000000  doc_1076         3      0\n",
       "18             0.000000  doc_1096         3      0\n",
       "19             0.000000  doc_1233         3      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@K 0.9\n",
      "AP@K 0.89\n",
      "R@K 1.0\n",
      "RR@K 1.0\n",
      "MAP@K (0.908478835978836, [1.0, 0.8354365079365079, 0.89])\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "ground_truth_queries = {\n",
    "    1:\"Landfall in South Carolina\",\n",
    "    2:\"Help and recovery during the hurricanee disaster\",\n",
    "    3:\"Floodings in South Carolina\"}\n",
    "\n",
    "final = pd.DataFrame()\n",
    "for query_id, query in ground_truth_queries.items():\n",
    "    ranking = search_tf_idf_subset(query, new_index, set(ground_truth[ground_truth['query_id']==query_id]['doc']))\n",
    "    print(\"\\n======================\\nResults for the subset of docs in the ground truth query '{}':\\n\".format(query))\n",
    "    rankingdf = pd.DataFrame(ranking, columns=['predicted_relevance', 'doc']).merge(ground_truth[ground_truth['query_id']==query_id], how='outer', on='doc').fillna(0)\n",
    "    display(rankingdf)\n",
    "    print(\"P@K\",precision_at_k(rankingdf['label'] ))\n",
    "    print(\"AP@K\",avg_precision_at_k(rankingdf['label'] ))\n",
    "    print(\"R@K\", recall(rankingdf['label']))\n",
    "    print(\"RR@K\",rr_at_k(rankingdf['label']))\n",
    "    if final.empty:\n",
    "        final = rankingdf\n",
    "    else:\n",
    "        final = pd.concat([final, rankingdf])\n",
    "\n",
    "print(\"MAP@K\",map_at_k(final))\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(doc_score, k=10): #binary relevance, predicted relevance, k for a given query\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_score: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    precision @k : float\n",
    "\n",
    "    \"\"\"\n",
    "    doc_score = doc_score[:k]\n",
    "    relevant = sum(doc_score == 1) #get number of relevant documents\n",
    "    return float(relevant) / k #calculae precision at k, which is the number of relevant documents trieved at k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_precision_at_k(doc_score, k=10): #binary relevance, predicted relevance, k for a given query\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_score: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    average precision @k : float\n",
    "    \"\"\"\n",
    "    gtp = np.sum(doc_score == 1) #Total number of gt positives\n",
    "    doc_score = doc_score[:k] #same as for precision\n",
    "    ## if all documents are not relevant\n",
    "    if gtp == 0:\n",
    "        return 0\n",
    "    n_relevant_at_i = 0\n",
    "    prec_at_i = 0\n",
    "    for i in range(len(doc_score)):\n",
    "        if doc_score[i] == 1: #only add the P@k when the doc is relevant\n",
    "            n_relevant_at_i += 1\n",
    "            prec_at_i += n_relevant_at_i / (i + 1) #calculate P@K (#docs relevant at k/k)\n",
    "    return prec_at_i / gtp #return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_at_k(search_res, k=10): #receives all the search esults dataframe containing all the queries and the results and relevances\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    search_res: search results dataset containing:\n",
    "        query_id: query id.\n",
    "        doc: document id.\n",
    "        predicted_relevance: relevance predicted through LightGBM.\n",
    "        label: actual score of the document for the query (ground truth).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mean average precision @ k : float\n",
    "    \"\"\"\n",
    "    avp = []\n",
    "    for q in search_res[\"query_id\"].unique():  # loop over all query ids\n",
    "        curr_data = search_res[search_res[\"query_id\"] == q]  # select data for current query (get a slice of the dataframe keeping only the data related to the current query)\n",
    "        avp.append(avg_precision_at_k(np.array(curr_data[\"label\"]), k))  #append average precision for current query\n",
    "    return np.sum(avp) / len(avp), avp  # return mean average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rr_at_k(doc_score, k=10):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_score: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Reciprocal Rank for qurrent query\n",
    "    \"\"\"\n",
    "\n",
    "    doc_score = doc_score[:k]\n",
    "    if np.sum(doc_score) == 0:  # if there are not relevant doument return 0\n",
    "        return 0\n",
    "    return 1 / (np.argmax(doc_score == 1) + 1)  # hint: to get the position of the first relevant document use \"np.argmax\" (+1 because the idex starts from 0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96daddbc09d577a7a9fec2f2b98a6c3a4cfa458e36ff25bf9550036ca06c436f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
