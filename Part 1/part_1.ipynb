{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from array import array\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "from numpy import linalg as la\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets read: 4000\n"
     ]
    }
   ],
   "source": [
    "data_folder = './data/'\n",
    "output_folder = './output/'\n",
    "\n",
    "data_path = data_folder + 'tw_hurricane_data.json'\n",
    "map_path = data_folder + 'tweet_document_ids_map.csv'\n",
    "\n",
    "# Reading every line in the input file.\n",
    "with open(data_path) as file:\n",
    "    lines = file.readlines()\n",
    "    \n",
    "print(\"Total number of tweets read: {}\".format(len(lines)))\n",
    "\n",
    "# Reading each json line\n",
    "lines = [json.loads(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Preprocess the tweet text by lower-casing all characters, tokenizing,\n",
    "    removing non-alphanumerics and stopwords and stemming.\n",
    "    \n",
    "    Argument:\n",
    "    text -- string (text) to be preprocessed\n",
    "    \n",
    "    Returns:\n",
    "    text - a list of tokens corresponding to the input text after the preprocessing.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    text = text.lower() ## Lower-casing all characters.\n",
    "    text = word_tokenize(text) ## Tokenizing the text.\n",
    "    text = [token for token in text if token.isalpha()] ## Removing non-alphanumeric tokens.\n",
    "    text = [x for x in text if x not in stop_words] ## Removing stop words.\n",
    "    text = [stemmer.stem(x) for x in text] ## Stemming the remaining tokens.\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import NaN\n",
    "\n",
    "\n",
    "def feature_extraction(tweet_line):\n",
    "    \"\"\"\n",
    "    Extract the fundamental information of a tweet.\n",
    "    \n",
    "    Argument:\n",
    "    tweet_line -- JSON with all the information of a tweet\n",
    "    \n",
    "    Returns:\n",
    "    tweet - a dictionary that contains de following fields: Text (Unprocessed), \n",
    "            Username, Date, Hashtags, Mentions, Likes, Retweets, Url and Clean Text\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    tweet = {}\n",
    "    tweet['Id'] = tweet_line['id']\n",
    "    tweet['Text'] = tweet_line['full_text']\n",
    "    tweet['Username'] = tweet_line['user']['screen_name']\n",
    "    tweet['Date'] = tweet_line['created_at']\n",
    "    tweet['Hashtags'] = [x['text'] for x in tweet_line['entities']['hashtags']]\n",
    "    mentions = re.findall(\"@([a-zA-Z0-9_]{1,50})\", tweet['Text'])\n",
    "    tweet['Mentions'] = mentions if len(mentions) != 0 else NaN\n",
    "    tweet['Likes'] = tweet_line['favorite_count']\n",
    "    tweet['Retweets'] = tweet_line['retweet_count']\n",
    "    tweet['Url'] = 'https://twitter.com/'+tweet['Username']+'/status/'+tweet_line['id_str']\n",
    "    tweet['Clean_text'] = clean(re.sub(r'http\\S+', '', tweet_line['full_text']))\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id: \t\t1575902788558667780\n",
      "Default tweet: \t'Palm Beach County Food Bank is alleviating hunger and supporting those impacted by #HurricaneIan \\n\\nDonate #crypto to @FoodBankPBC: https://t.co/VFpF91oeQM'\n",
      "Clean Tweet: \t['palm', 'beach', 'counti', 'food', 'bank', 'allevi', 'hunger', 'support', 'impact', 'hurricaneian', 'donat', 'crypto', 'foodbankpbc']\n",
      "Username: \tTheGivingBlock\n",
      "Date: \t\tFri Sep 30 17:37:58 +0000 2022\n",
      "Hashtags: \t['HurricaneIan', 'crypto']\n",
      "Mentions: \t['FoodBankPBC']\n",
      "Likes: \t\t1\n",
      "Retweets: \t0\n",
      "Url: \t\thttps://twitter.com/TheGivingBlock/status/1575902788558667780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l = random.randint(0, len(lines)-1)\n",
    "new_tweet = feature_extraction(lines[l])\n",
    "\n",
    "print('Id: \\t\\t{}'.format(new_tweet['Id']))\n",
    "print('Default tweet: \\t' + repr(new_tweet['Text']))\n",
    "print('Clean Tweet: \\t{}'.format(new_tweet['Clean_text']))\n",
    "print('Username: \\t{}'.format(new_tweet['Username']))\n",
    "print('Date: \\t\\t{}'.format(new_tweet['Date']))\n",
    "print('Hashtags: \\t{}'.format(new_tweet['Hashtags']))\n",
    "print('Mentions: \\t{}'.format(new_tweet['Mentions']))\n",
    "print('Likes: \\t\\t{}'.format(new_tweet['Likes']))\n",
    "print('Retweets: \\t{}'.format(new_tweet['Retweets']))\n",
    "print('Url: \\t\\t{}\\n'.format(new_tweet['Url']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tweets_df(tweets):\n",
    "    \"\"\"\n",
    "    Build a dataframe from all tweets JSON.\n",
    "    \n",
    "    Argument:\n",
    "    tweets -- JSON list with all tweets' information\n",
    "    \n",
    "    Returns:\n",
    "    df - a dataframe that contains de information of all tweets\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    tweet_dict = defaultdict(list)\n",
    "\n",
    "    for i, tweet in enumerate(tweets):\n",
    "\n",
    "        tweet_data = feature_extraction(tweet)\n",
    "        for key, value in tweet_data.items():\n",
    "            tweet_dict[key].append(value)\n",
    "\n",
    "        if i%500 == 0:\n",
    "            print('Tweets processed: {}'.format(i))\n",
    "\n",
    "    return pd.DataFrame(tweet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets processed: 0\n",
      "Tweets processed: 500\n",
      "Tweets processed: 1000\n",
      "Tweets processed: 1500\n",
      "Tweets processed: 2000\n",
      "Tweets processed: 2500\n",
      "Tweets processed: 3000\n",
      "Tweets processed: 3500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Url</th>\n",
       "      <th>Clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1575918182698979328</td>\n",
       "      <td>So this will keep spinning over us until 7 pmâ€¦...</td>\n",
       "      <td>suzjdean</td>\n",
       "      <td>Fri Sep 30 18:39:08 +0000 2022</td>\n",
       "      <td>[HurricaneIan]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/suzjdean/status/1575918182...</td>\n",
       "      <td>[keep, spin, us, away, alreadi, hurricaneian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1575918151862304768</td>\n",
       "      <td>Our hearts go out to all those affected by #Hu...</td>\n",
       "      <td>lytx</td>\n",
       "      <td>Fri Sep 30 18:39:01 +0000 2022</td>\n",
       "      <td>[HurricaneIan]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/lytx/status/15759181518623...</td>\n",
       "      <td>[heart, go, affect, hurricaneian, wish, everyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1575918140839673873</td>\n",
       "      <td>Kissimmee neighborhood off of Michigan Ave. \\n...</td>\n",
       "      <td>CHeathWFTV</td>\n",
       "      <td>Fri Sep 30 18:38:58 +0000 2022</td>\n",
       "      <td>[HurricaneIan]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/CHeathWFTV/status/15759181...</td>\n",
       "      <td>[kissimme, neighborhood, michigan, hurricaneian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1575918135009738752</td>\n",
       "      <td>I have this one tree in my backyard that scare...</td>\n",
       "      <td>spiralgypsy</td>\n",
       "      <td>Fri Sep 30 18:38:57 +0000 2022</td>\n",
       "      <td>[scwx, HurricaneIan]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/spiralgypsy/status/1575918...</td>\n",
       "      <td>[one, tree, backyard, scare, poltergeist, tree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1575918119251419136</td>\n",
       "      <td>@AshleyRuizWx @Stephan89441722 @lilmizzheidi @...</td>\n",
       "      <td>Blondie610</td>\n",
       "      <td>Fri Sep 30 18:38:53 +0000 2022</td>\n",
       "      <td>[HurricaneIan]</td>\n",
       "      <td>[AshleyRuizWx, Stephan89441722, lilmizzheidi, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/Blondie610/status/15759181...</td>\n",
       "      <td>[ashleyruizwx, lilmizzheidi, winknew, dylanfed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id                                               Text  \\\n",
       "0  1575918182698979328  So this will keep spinning over us until 7 pmâ€¦...   \n",
       "1  1575918151862304768  Our hearts go out to all those affected by #Hu...   \n",
       "2  1575918140839673873  Kissimmee neighborhood off of Michigan Ave. \\n...   \n",
       "3  1575918135009738752  I have this one tree in my backyard that scare...   \n",
       "4  1575918119251419136  @AshleyRuizWx @Stephan89441722 @lilmizzheidi @...   \n",
       "\n",
       "      Username                            Date              Hashtags  \\\n",
       "0     suzjdean  Fri Sep 30 18:39:08 +0000 2022        [HurricaneIan]   \n",
       "1         lytx  Fri Sep 30 18:39:01 +0000 2022        [HurricaneIan]   \n",
       "2   CHeathWFTV  Fri Sep 30 18:38:58 +0000 2022        [HurricaneIan]   \n",
       "3  spiralgypsy  Fri Sep 30 18:38:57 +0000 2022  [scwx, HurricaneIan]   \n",
       "4   Blondie610  Fri Sep 30 18:38:53 +0000 2022        [HurricaneIan]   \n",
       "\n",
       "                                            Mentions  Likes  Retweets  \\\n",
       "0                                                NaN      0         0   \n",
       "1                                                NaN      0         0   \n",
       "2                                                NaN      0         0   \n",
       "3                                                NaN      0         0   \n",
       "4  [AshleyRuizWx, Stephan89441722, lilmizzheidi, ...      0         0   \n",
       "\n",
       "                                                 Url  \\\n",
       "0  https://twitter.com/suzjdean/status/1575918182...   \n",
       "1  https://twitter.com/lytx/status/15759181518623...   \n",
       "2  https://twitter.com/CHeathWFTV/status/15759181...   \n",
       "3  https://twitter.com/spiralgypsy/status/1575918...   \n",
       "4  https://twitter.com/Blondie610/status/15759181...   \n",
       "\n",
       "                                          Clean_text  \n",
       "0      [keep, spin, us, away, alreadi, hurricaneian]  \n",
       "1  [heart, go, affect, hurricaneian, wish, everyo...  \n",
       "2   [kissimme, neighborhood, michigan, hurricaneian]  \n",
       "3  [one, tree, backyard, scare, poltergeist, tree...  \n",
       "4  [ashleyruizwx, lilmizzheidi, winknew, dylanfed...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = build_tweets_df(lines)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading map file as a dataframe\n",
    "df = pd.read_csv(map_path, delimiter='\\t', names=['Document', 'Id'])\n",
    "\n",
    "tweets_df = pd.merge(df,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Url</th>\n",
       "      <th>Clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc_1</td>\n",
       "      <td>1575918182698979328</td>\n",
       "      <td>So this will keep spinning over us until 7 pmâ€¦...</td>\n",
       "      <td>suzjdean</td>\n",
       "      <td>Fri Sep 30 18:39:08 +0000 2022</td>\n",
       "      <td>[HurricaneIan]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/suzjdean/status/1575918182...</td>\n",
       "      <td>[keep, spin, us, away, alreadi, hurricaneian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc_2</td>\n",
       "      <td>1575918151862304768</td>\n",
       "      <td>Our hearts go out to all those affected by #Hu...</td>\n",
       "      <td>lytx</td>\n",
       "      <td>Fri Sep 30 18:39:01 +0000 2022</td>\n",
       "      <td>[HurricaneIan]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/lytx/status/15759181518623...</td>\n",
       "      <td>[heart, go, affect, hurricaneian, wish, everyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc_3</td>\n",
       "      <td>1575918140839673873</td>\n",
       "      <td>Kissimmee neighborhood off of Michigan Ave. \\n...</td>\n",
       "      <td>CHeathWFTV</td>\n",
       "      <td>Fri Sep 30 18:38:58 +0000 2022</td>\n",
       "      <td>[HurricaneIan]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/CHeathWFTV/status/15759181...</td>\n",
       "      <td>[kissimme, neighborhood, michigan, hurricaneian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc_4</td>\n",
       "      <td>1575918135009738752</td>\n",
       "      <td>I have this one tree in my backyard that scare...</td>\n",
       "      <td>spiralgypsy</td>\n",
       "      <td>Fri Sep 30 18:38:57 +0000 2022</td>\n",
       "      <td>[scwx, HurricaneIan]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/spiralgypsy/status/1575918...</td>\n",
       "      <td>[one, tree, backyard, scare, poltergeist, tree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc_5</td>\n",
       "      <td>1575918119251419136</td>\n",
       "      <td>@AshleyRuizWx @Stephan89441722 @lilmizzheidi @...</td>\n",
       "      <td>Blondie610</td>\n",
       "      <td>Fri Sep 30 18:38:53 +0000 2022</td>\n",
       "      <td>[HurricaneIan]</td>\n",
       "      <td>[AshleyRuizWx, Stephan89441722, lilmizzheidi, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/Blondie610/status/15759181...</td>\n",
       "      <td>[ashleyruizwx, lilmizzheidi, winknew, dylanfed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Document                   Id  \\\n",
       "0    doc_1  1575918182698979328   \n",
       "1    doc_2  1575918151862304768   \n",
       "2    doc_3  1575918140839673873   \n",
       "3    doc_4  1575918135009738752   \n",
       "4    doc_5  1575918119251419136   \n",
       "\n",
       "                                                Text     Username  \\\n",
       "0  So this will keep spinning over us until 7 pmâ€¦...     suzjdean   \n",
       "1  Our hearts go out to all those affected by #Hu...         lytx   \n",
       "2  Kissimmee neighborhood off of Michigan Ave. \\n...   CHeathWFTV   \n",
       "3  I have this one tree in my backyard that scare...  spiralgypsy   \n",
       "4  @AshleyRuizWx @Stephan89441722 @lilmizzheidi @...   Blondie610   \n",
       "\n",
       "                             Date              Hashtags  \\\n",
       "0  Fri Sep 30 18:39:08 +0000 2022        [HurricaneIan]   \n",
       "1  Fri Sep 30 18:39:01 +0000 2022        [HurricaneIan]   \n",
       "2  Fri Sep 30 18:38:58 +0000 2022        [HurricaneIan]   \n",
       "3  Fri Sep 30 18:38:57 +0000 2022  [scwx, HurricaneIan]   \n",
       "4  Fri Sep 30 18:38:53 +0000 2022        [HurricaneIan]   \n",
       "\n",
       "                                            Mentions  Likes  Retweets  \\\n",
       "0                                                NaN      0         0   \n",
       "1                                                NaN      0         0   \n",
       "2                                                NaN      0         0   \n",
       "3                                                NaN      0         0   \n",
       "4  [AshleyRuizWx, Stephan89441722, lilmizzheidi, ...      0         0   \n",
       "\n",
       "                                                 Url  \\\n",
       "0  https://twitter.com/suzjdean/status/1575918182...   \n",
       "1  https://twitter.com/lytx/status/15759181518623...   \n",
       "2  https://twitter.com/CHeathWFTV/status/15759181...   \n",
       "3  https://twitter.com/spiralgypsy/status/1575918...   \n",
       "4  https://twitter.com/Blondie610/status/15759181...   \n",
       "\n",
       "                                          Clean_text  \n",
       "0      [keep, spin, us, away, alreadi, hurricaneian]  \n",
       "1  [heart, go, affect, hurricaneian, wish, everyo...  \n",
       "2   [kissimme, neighborhood, michigan, hurricaneian]  \n",
       "3  [one, tree, backyard, scare, poltergeist, tree...  \n",
       "4  [ashleyruizwx, lilmizzheidi, winknew, dylanfed...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
